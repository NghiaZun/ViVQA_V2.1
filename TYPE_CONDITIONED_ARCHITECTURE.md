# ğŸ”¥ TYPE-CONDITIONED MULTI-TASK VQA ARCHITECTURE

## âœ… ÄÃƒ IMPLEMENT (Theo tinh tháº§n Viblo article)

Kiáº¿n trÃºc **SOFT MULTI-TASK + TYPE-CONDITIONED GENERATION**

---

## ğŸ§  TRIáº¾T LÃ THIáº¾T Káº¾

### âŒ KHÃ”NG lÃ m (Hard Pipeline)
```
Question â†’ [IF type==COLOR] â†’ Color vocab only
         â†’ [IF type==COUNT] â†’ Number vocab only
         â†’ Hard decision, brittle
```

### âœ… LÃ€M (Soft Multi-task)
```
Question â†’ Type head (auxiliary signal)
         â†“
    Type embedding
         â†“
(Type + Question) â†’ Gate vision patches (soft attention)
         â†“
Type-conditioned features â†’ Decoder
         â†“
Type bias logits (soft reweighting, not masking!)
```

---

## ğŸ”¥ KIáº¾N TRÃšC CHI TIáº¾T

### 1ï¸âƒ£ Type Prediction Head (Auxiliary Task)

**Má»¥c Ä‘Ã­ch:** Báº¯t question encoder há»c khÃ¡i niá»‡m "type" (nhÆ°ng khÃ´ng dÃ¹ng Ä‘á»ƒ quyáº¿t Ä‘á»‹nh cá»©ng)

```python
class TypePredictionHead(nn.Module):
    """
    Types:
        0 = OBJECT (ÄÃ¢y lÃ  gÃ¬?)
        1 = COUNT (CÃ³ bao nhiÃªu?)
        2 = COLOR (MÃ u gÃ¬?)
        3 = LOCATION (á» Ä‘Ã¢u?)
    """
    def forward(self, text_cls):
        # text_cls: [B, D] - CLS token from question
        return self.classifier(text_cls)  # [B, 4]
```

**Loss:**
```python
type_loss = CrossEntropy(type_logits, ground_truth_types)
# Î» = 0.2 â†’ auxiliary signal, khÃ´ng dominates
total_loss = answer_loss + 0.2 * type_loss
```

---

### 2ï¸âƒ£ Type-Conditioned Vision Gating

**Key Idea:** Question types cáº§n vision features khÃ¡c nhau

| Type | Vision Focus |
|------|-------------|
| COLOR | Color-rich patches |
| COUNT | Object distribution (global) |
| LOCATION | Spatial arrangement |
| OBJECT | Salient regions |

**Implementation:**
```python
class VisionGating(nn.Module):
    def __init__(self, hidden_dim, num_types=4):
        self.type_embedding = nn.Embedding(num_types, hidden_dim)
        self.query_proj = nn.Linear(hidden_dim * 2, hidden_dim)
        self.gate_net = ...  # Attention mechanism
    
    def forward(self, vision, text, type_ids):
        # 1. Embed type
        type_emb = self.type_embedding(type_ids)  # [B, D]
        
        # 2. Combine (question_cls + type)
        query = concat([text_cls, type_emb])  # [B, 2D]
        query = self.query_proj(query)  # [B, D]
        
        # 3. Attention: query @ vision â†’ Î± (importance)
        alpha = gate_net(concat([vision, query]))  # [B, P]
        
        # 4. Gated vision
        gated = alpha * vision + (1-alpha) * text_context
        return gated
```

**Hiá»‡u á»©ng:**
- COUNT question â†’ Î± cao á»Ÿ patches chá»©a objects
- COLOR question â†’ Î± cao á»Ÿ patches cÃ³ mÃ u ná»•i
- LOCATION question â†’ Î± cao á»Ÿ patches khÃ´ng gian

---

### 3ï¸âƒ£ Type-Aware Logits Biasing

**Má»¥c Ä‘Ã­ch:** HÆ°á»›ng decoder vá» answer space há»£p lÃ½ (SOFT, khÃ´ng cháº·n!)

```python
class TypeAwareLogitsBias(nn.Module):
    def __init__(self, vocab_size, num_types=4):
        # Learnable bias per type: [num_types, vocab_size]
        self.type_biases = nn.Parameter(
            torch.randn(num_types, vocab_size) * 0.1
        )
    
    def forward(self, base_logits, type_ids):
        bias = self.type_biases[type_ids]  # [B, vocab_size]
        return base_logits + bias  # SOFT reweighting!
```

**VÃ­ dá»¥:**
- Type=COLOR â†’ `type_biases[2]` boost logits cá»§a `["Ä‘á»", "xanh", "vÃ ng", ...]`
- Type=COUNT â†’ `type_biases[1]` boost logits cá»§a `["má»™t", "hai", "1", "2", ...]`
- Type=LOCATION â†’ `type_biases[3]` boost logits cá»§a `["trÃªn", "dÆ°á»›i", "trÃ¡i", "pháº£i", ...]`

**âš ï¸ QUAN TRá»ŒNG:**
- Tokens ngoÃ i preferred vocab **VáºªN CÃ“ xÃ¡c suáº¥t**
- Chá»‰ tháº¥p hÆ¡n, khÃ´ng bá»‹ mask hoÃ n toÃ n
- Model váº«n tá»± do sinh, khÃ´ng bá»‹ Ä‘Ã³ng khung

---

## ğŸ”„ LUá»’NG FORWARD PASS

```python
def forward(pixel_values, input_ids, labels, question_types):
    # 1. Encode question
    text_features = text_encoder(input_ids)
    text_cls = text_features[:, 0, :]
    
    # 2. ğŸ”¥ Type prediction (auxiliary)
    type_logits = type_head(text_cls)
    type_loss = CE(type_logits, question_types)
    
    # 3. Encode vision
    vision_features = vision_encoder(pixel_values)
    
    # 4. Fusion (Flamingo cross-attention)
    fused_vision = flamingo_fusion(vision_features, text_features)
    
    # 5. ğŸ”¥ Type-conditioned vision gating
    gated_vision = vision_gating(
        fused_vision, 
        text_features,
        type_ids=question_types  # Use GT during training
    )
    
    # 6. Decoder
    decoder_out = decoder(
        encoder_hidden_states=concat([gated_vision, text_features])
    )
    
    # 7. Generate logits
    base_logits = lm_head(decoder_out)
    
    # 8. ğŸ”¥ Type-aware biasing
    answer_logits = logits_bias(base_logits, question_types)
    
    # 9. ğŸ”¥ Multi-task loss
    answer_loss = CE(answer_logits, labels)
    total_loss = answer_loss + 0.2 * type_loss
    
    return answer_logits, total_loss, type_loss
```

---

## ğŸ¯ Táº I SAO KIáº¾N TRÃšC NÃ€Y ÄÃšNG?

### âœ… Giá»¯ Ä‘Æ°á»£c generative nature
- Model váº«n sinh tá»± do, khÃ´ng bá»‹ rule-based answer
- Type chá»‰ lÃ  **soft signal**, khÃ´ng pháº£i hard decision

### âœ… Vision thá»±c sá»± quyáº¿t Ä‘á»‹nh ná»™i dung
- Gating theo type â†’ cÃ¡c type nhÃ¬n patches khÃ¡c nhau
- COUNT nhÃ¬n distribution, COLOR nhÃ¬n mÃ u, LOCATION nhÃ¬n khÃ´ng gian

### âœ… Question chá»‰ quyáº¿t Ä‘á»‹nh "cÃ¡ch nhÃ¬n"
- Question text â†’ type â†’ cÃ¡ch select vision
- Vision content â†’ answer details

### âœ… KhÃ´ng hack, khÃ´ng cheat
- KhÃ´ng if-else trong code
- KhÃ´ng hard mask vocab
- Má»i thá»© learnable, differentiable

### âœ… ÄÃºng tinh tháº§n multi-task learning hiá»‡n Ä‘áº¡i
- Auxiliary type loss giÃºp question encoder há»c pattern
- Type embedding giÃºp vision gating adapt
- Logits bias giÃºp decoder focus answer space
- NhÆ°ng táº¥t cáº£ Ä‘á»u SOFT, model váº«n cÃ³ quyá»n tá»± do!

---

## ğŸ“Š TRAINING

### Dataset
```python
# Auto-detect type from Vietnamese patterns
def detect_question_type(question: str) -> int:
    if re.search(r'mÃ u\s*(gÃ¬|sáº¯c)', question):
        return 2  # COLOR
    if re.search(r'(bao nhiÃªu|máº¥y)', question):
        return 1  # COUNT
    if re.search(r'(á»Ÿ\s*Ä‘Ã¢u|trÃªn|dÆ°á»›i)', question):
        return 3  # LOCATION
    return 0  # OBJECT (default)

dataset = VQAGenDataset(
    csv_path='train.csv',
    include_question_type=True,
    auto_detect_type=True  # Auto-detect from question
)
```

### Command
```bash
python train_no_latent.py \
    --train_csv train.csv \
    --image_dir images/ \
    --use_vision_gate \       # Enable type-conditioned gating
    --use_type_loss \         # Enable multi-task type loss
    --epochs 50 \
    --batch_size 32 \
    --lr 2e-4
```

### Expected Metrics
```
Epoch 1: loss=2.45 ans=2.30 type=0.15 Î±_mean=0.65
Epoch 10: loss=1.20 ans=1.10 type=0.10 Î±_mean=0.72
Epoch 50: loss=0.45 ans=0.42 type=0.03 Î±_mean=0.80
```

**Type loss giáº£m nhanh:** Question encoder há»c type pattern
**Î±_mean tÄƒng:** Vision gating há»c select patches quan trá»ng
**Answer loss giáº£m á»•n Ä‘á»‹nh:** Multi-task learning work!

---

## ğŸ”¬ SO SÃNH Vá»šI CÃCH CÅ¨

### âŒ CÃ¡ch cÅ© (Hard Pipeline)
```python
if type == COLOR:
    vocab_mask = color_vocab_only
elif type == COUNT:
    vocab_mask = number_vocab_only
answer = generate(logits * vocab_mask)
```

**Váº¥n Ä‘á»:**
- âŒ Type prediction sai â†’ toÃ n bá»™ answer sai
- âŒ KhÃ´ng há»c Ä‘Æ°á»£c tá»« gradient (discrete decision)
- âŒ Rigid, khÃ´ng generalize

### âœ… CÃ¡ch má»›i (Soft Multi-task)
```python
type_emb = embed(predicted_type)  # Differentiable
vision = gate(vision, type_emb)    # Soft attention
logits = decoder(vision) + type_bias  # Soft reweighting
```

**Æ¯u Ä‘iá»ƒm:**
- âœ… Type prediction sai â†’ váº«n cÃ³ gradient flow
- âœ… Soft signal â†’ model tá»± há»c balance
- âœ… Flexible, generalize tá»‘t hÆ¡n

---

## ğŸš€ NEXT STEPS

1. **Train vá»›i type-conditioned architecture:**
   ```bash
   python train_no_latent.py --use_vision_gate --use_type_loss
   ```

2. **Monitor metrics:**
   - Type accuracy (auxiliary task)
   - Î±_mean, Î±_std (vision gating behavior)
   - Answer EM/F1 (main task)

3. **Analyze learned biases:**
   ```python
   # Check what tokens are boosted per type
   type_biases = model.logits_bias.type_biases
   top_tokens_per_type = torch.topk(type_biases, k=20, dim=-1)
   ```

4. **Visualize attention maps:**
   ```python
   # See which patches are attended for each type
   gate_values = model.vision_gating(...)
   # gate_values: [B, 256] - importance per patch
   ```

---

## âœ¨ TÃ“M Táº®T

**Kiáº¿n trÃºc nÃ y implement Ä‘Ãºng tinh tháº§n Viblo article:**

1. âœ… **Multi-task soft:** Type lÃ  auxiliary signal, khÃ´ng pháº£i hard decision
2. âœ… **Type-conditioned generation:** Type â†’ gate vision â†’ bias logits (all soft!)
3. âœ… **KhÃ´ng hack:** Má»i thá»© learnable, differentiable, no if-else
4. âœ… **Vision-driven:** Vision content quyáº¿t Ä‘á»‹nh answer, question quyáº¿t Ä‘á»‹nh "cÃ¡ch nhÃ¬n"

**ÄÃºng cÃ¢u báº¡n há»i:**
> "question â†’ type, má»—i type thÃ¬ gated vision vÃ o question pháº£i khÃ´ng?"

ğŸ‘‰ **ÄÃšNG!** Question â†’ learn type â†’ (type + question) â†’ gate vision â†’ answer

KhÃ´ng pháº£i: question â†’ type â†’ rule-based answer âŒ
